# Schematic - Project Context

## Overview
Schematic is a comprehensive toolkit for managing Databricks Unity Catalog schemas using a declarative, version-controlled approach. It consists of a VS Code extension for visual schema design and a Python SDK/CLI for automation and CI/CD integration.

## ğŸ”¥ Quick Rules (Always Follow)

1. **Type Annotations**: ALL Python functions must have parameter and return types (see Python section)
2. **Formatting**: Ruff format with 100 char line length (auto on save)
3. **Testing**: Run pytest before commit (169 passed, 12 skipped)
4. **Logging**: Use `outputChannel.appendLine()` in extension (never `console.log()`)
5. **Immutability**: Never mutate state directly, always create new objects

## Repository Structure (Monorepo)

```
schematic/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ vscode-extension/       # VS Code Extension (TypeScript + React)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ extension.ts           # Extension commands
â”‚   â”‚   â”‚   â”œâ”€â”€ storage-v4.ts          # V4 file storage (multi-environment)
â”‚   â”‚   â”‚   â”œâ”€â”€ providers/             # Provider-based architecture
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base/             # Base provider contracts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models.ts     # Zod schemas
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ operations.ts # Operation definitions
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ sql-generator.ts # SQL generation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ unity/            # Unity Catalog provider
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ sql-generator.ts
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ state-reducer.ts
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ operations.ts
â”‚   â”‚   â”‚   â””â”€â”€ webview/               # React UI
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚
â”‚   â””â”€â”€ python-sdk/             # Python SDK & CLI
â”‚       â”œâ”€â”€ src/schematic/
â”‚       â”‚   â”œâ”€â”€ providers/             # Provider-based architecture
â”‚       â”‚   â”‚   â”œâ”€â”€ base/             # Base provider contracts
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ models.py     # Pydantic models
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ operations.py # Operation types
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ sql_generator.py  # SQL generation
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ provider.py   # Provider protocol
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ executor.py   # SQL execution protocol
â”‚       â”‚   â”‚   â”œâ”€â”€ unity/            # Unity Catalog provider
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ models.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ operations.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ sql_generator.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ state_reducer.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ provider.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py       # Databricks authentication
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ executor.py   # Databricks SQL executor
â”‚       â”‚   â”‚   â””â”€â”€ registry.py       # Provider registry
â”‚       â”‚   â”œâ”€â”€ commands/              # CLI command modules
â”‚       â”‚   â”‚   â”œâ”€â”€ apply.py          # Apply command
â”‚       â”‚   â”‚   â”œâ”€â”€ sql.py            # SQL generation command
â”‚       â”‚   â”‚   â”œâ”€â”€ validate.py       # Validation command
â”‚       â”‚   â”‚   â””â”€â”€ deployment.py     # Deployment recording
â”‚       â”‚   â”œâ”€â”€ storage_v4.py          # V4 file storage (multi-environment)
â”‚       â”‚   â”œâ”€â”€ storage_v3.py          # V3 file storage (deprecated)
â”‚       â”‚   â”œâ”€â”€ deployment_tracker.py  # Deployment tracking
â”‚       â”‚   â””â”€â”€ cli.py                 # CLI routing layer
â”‚       â””â”€â”€ pyproject.toml
â”‚
â”œâ”€â”€ examples/                   # Working examples
â”‚   â”œâ”€â”€ basic-schema/          # Sample project
â”‚   â”œâ”€â”€ github-actions/        # CI/CD templates
â”‚   â””â”€â”€ python-scripts/        # SDK usage examples
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ README.md              # Documentation index
â”‚   â”œâ”€â”€ QUICKSTART.md          # Getting started guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md        # Technical design
â”‚   â””â”€â”€ DEVELOPMENT.md         # Development guide
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ smoke-test.sh          # Quick validation
â”‚
â”œâ”€â”€ .github/workflows/          # CI/CD pipelines
â”‚   â”œâ”€â”€ extension-ci.yml
â”‚   â”œâ”€â”€ python-sdk-ci.yml
â”‚   â””â”€â”€ integration-tests.yml
â”‚
â”œâ”€â”€ README.md                   # Project overview
â”œâ”€â”€ TESTING.md                  # Testing guide
â”œâ”€â”€ CONTRIBUTING.md             # Contributing guidelines
â””â”€â”€ .cursorrules               # This file
```

## Architecture (V4)

### File Structure (.schematic/)
```
project-root/
â””â”€â”€ .schematic/
    â”œâ”€â”€ project.json           # Project metadata (version, snapshots list, settings)
    â”œâ”€â”€ changelog.json         # Working changes (ops since last snapshot)
    â”œâ”€â”€ snapshots/
    â”‚   â”œâ”€â”€ v0.1.0.json       # Full state snapshots
    â”‚   â”œâ”€â”€ v0.2.0.json
    â”‚   â””â”€â”€ v0.3.0.json
    â””â”€â”€ migrations/            # Generated SQL files
        â””â”€â”€ migration_*.sql
```

### Core Concepts

1. **Operations (Ops)**: Append-only log of all user actions
   - Each op has: `{id, ts, op, target, payload}`
   - Ops are immutable and never edited
   - Examples: `add_catalog`, `rename_column`, `reorder_columns`
   - All ops have UUIDs for tracking

2. **Changelog**: `changelog.json` contains ops since last snapshot
   - Cleared when snapshot is created
   - Tracks `sinceSnapshot` version
   - This is the "working directory" of changes

3. **Snapshots**: Point-in-time full state captures
   - Stored as separate files: `.schematic/snapshots/vX.Y.Z.json`
   - Contains complete state + list of ops included
   - Metadata stored in `project.json`, full state in snapshot file
   - Semantic versioning (v0.1.0, v0.2.0, etc.)

4. **State Loading**: 
   - Load latest snapshot (or start with empty state)
   - Apply changelog ops to get current state
   - This is what the UI displays

5. **SQL Generation**: 
   - Convert changelog ops to SQL DDL
   - Idempotent statements (safe to run multiple times)
   - Saved to `.schematic/migrations/` directory

### Data Models

**Project File** (`project.json` - v4 Schema):
```typescript
{
  version: 4,
  name: string,
  provider: {
    type: string,  // e.g., "unity"
    version: string,  // e.g., "1.0.0"
    environments: {
      [envName: string]: {
        topLevelName: string,  // Physical catalog name (for Unity Catalog)
        description?: string,
        allowDrift: boolean,
        requireSnapshot: boolean,
        requireApproval?: boolean,
        autoCreateTopLevel: boolean,
        autoCreateSchematicSchema: boolean
      }
    }
  },
  managedLocations: {  // Project-level managed locations (for catalog/schema MANAGED LOCATION)
    [locationName: string]: {
      paths: {
        [envName: string]: string  // Environment-specific physical paths
      },
      description?: string
    }
  },
  externalLocations: {  // Project-level external locations (for external tables)
    [locationName: string]: {
      paths: {
        [envName: string]: string  // Environment-specific physical paths
      },
      description?: string
    }
  },
  snapshots: SnapshotMetadata[], // Just metadata, references to files
  deployments: Deployment[],
  settings: ProjectSettings,
  latestSnapshot: string | null  // version string
}
```

**Note:** v4 refactors locations from environment-specific to project-level with per-environment paths, enabling consistent location names across environments while allowing different physical paths.

**Changelog File** (`changelog.json`):
```typescript
{
  version: 1,
  sinceSnapshot: string | null,  // version
  ops: Op[],
  lastModified: string  // ISO timestamp
}
```

**Snapshot File** (`.schematic/snapshots/vX.Y.Z.json`):
```typescript
{
  id: string,
  version: string,
  name: string,
  ts: string,
  createdBy: string,
  state: { catalogs: Catalog[] },  // Full state
  opsIncluded: string[],  // Op IDs
  previousSnapshot: string | null,
  hash: string,  // SHA-256 for integrity
  tags: string[],
  comment?: string
}
```

**Unity Catalog Model** (Enhanced with Governance & Storage Features):
```
Catalog
â”œâ”€â”€ id, name
â”œâ”€â”€ managedLocationName?: string                       // Reference to project-level managed location
â”œâ”€â”€ Schema[]
    â”œâ”€â”€ id, name
    â”œâ”€â”€ managedLocationName?: string                   // Reference to project-level managed location
    â””â”€â”€ Table[]
        â”œâ”€â”€ id, name, format (delta/iceberg)
        â”œâ”€â”€ external?: boolean                         // Is external table
        â”œâ”€â”€ externalLocationName?: string              // Reference to project-level external location
        â”œâ”€â”€ path?: string                              // Relative path within external location
        â”œâ”€â”€ partitionColumns?: string[]                // PARTITIONED BY columns
        â”œâ”€â”€ clusterColumns?: string[]                  // CLUSTER BY columns (Liquid Clustering)
        â”œâ”€â”€ columns: Column[]
        â”‚   â”œâ”€â”€ id, name, type, nullable, comment
        â”‚   â”œâ”€â”€ tags?: Record<string, string>         // Column-level tags
        â”‚   â””â”€â”€ maskId?: string                        // Reference to column mask
        â”œâ”€â”€ properties: Record<string, string>         // TBLPROPERTIES
        â”œâ”€â”€ constraints: Constraint[]                  // PK, FK, CHECK
        â”œâ”€â”€ grants: Grant[]
        â”œâ”€â”€ rowFilters?: RowFilter[]                   // Row-level security
        â””â”€â”€ columnMasks?: ColumnMask[]                 // Column masking
```

**Column**:
```typescript
{
  id: string,
  name: string,
  type: string,
  nullable: boolean,
  comment?: string,
  tags?: Record<string, string>,    // { tag_name: tag_value }
  maskId?: string                    // Reference to active mask
}
```

**Constraint** (Supports PRIMARY KEY, FOREIGN KEY, CHECK):
```typescript
{
  id: string,
  type: 'primary_key' | 'foreign_key' | 'check',
  name?: string,                    // CONSTRAINT name
  columns: string[],                // column IDs
  
  // For PRIMARY KEY
  timeseries?: boolean,             
  
  // For FOREIGN KEY
  parentTable?: string,             
  parentColumns?: string[],         
  matchFull?: boolean,
  onUpdate?: 'NO_ACTION',
  onDelete?: 'NO_ACTION',
  
  // For CHECK
  expression?: string,              // SQL expression
  
  // Constraint options (all types)
  notEnforced?: boolean,            
  deferrable?: boolean,
  initiallyDeferred?: boolean,
  rely?: boolean                    // For Photon query optimization
}
```

**RowFilter** (Row-level security):
```typescript
{
  id: string,
  name: string,
  enabled: boolean,
  udfExpression: string,            // e.g., "region = current_user()"
  description?: string
}
```

**ColumnMask** (Column-level masking):
```typescript
{
  id: string,
  columnId: string,
  name: string,
  enabled: boolean,
  maskFunction: string,             // e.g., "REDACT_EMAIL(email)"
  description?: string
}
```

## VS Code Extension

### Storage Layer (`packages/vscode-extension/src/storage-v4.ts`)

**Key Functions**:
- `ensureProjectFile()` - Initialize new v4 project with environments
- `loadCurrentState()` - Load snapshot + apply changelog
- `appendOps()` - Add ops to changelog
- `createSnapshot()` - Create snapshot file, update metadata, clear changelog
- `readProject()`, `readChangelog()`, `readSnapshot()`
- `getEnvironmentConfig()` - Get environment-specific configuration

**Op Reducer**: `applyOpsToState()` applies ops to state immutably

**Catalog Mode**: Supports `single` mode with implicit catalog (`__implicit__`)

### SQL Generator (`packages/vscode-extension/src/providers/unity/sql-generator.ts`)

**UnitySQLGenerator class**:
- `generateSQL(ops: Op[]): string` - Main entry point
- Accepts `catalogNameMapping` for environment-specific SQL
- Private methods for each operation type
- Generates idempotent DDL (CREATE IF NOT EXISTS, etc.)
- Handles all 29 Unity Catalog operations
- Orders SQL by dependency (catalog â†’ schema â†’ table â†’ operations)
- Includes operation tracking in comments

### Extension (`packages/vscode-extension/src/extension.ts`)

**Commands**:
1. `schematic.openDesigner` - Opens React webview
2. `schematic.showLastOps` - Shows changelog ops
3. `schematic.createSnapshot` - Creates new snapshot
4. `schematic.generateSQL` - Generates SQL migration file

**Message Flow**:
- Webview â†’ Extension: `load-project`, `append-ops`
- Extension â†’ Webview: `project-loaded`, `project-updated`

### Webview (`packages/vscode-extension/src/webview/`)

**Architecture**: React + Vite + Zustand

**Components**:
- `App.tsx` - Main layout, message handling
- `Sidebar.tsx` - Tree view with context-aware inline "+" buttons
- `TableDesigner.tsx` - Comprehensive table editor
- `ColumnGrid.tsx` - Inline column editing + tags
- `TableProperties.tsx` - TBLPROPERTIES management
- `TableConstraints.tsx` - PRIMARY KEY, FOREIGN KEY, CHECK
- `SecurityGovernance.tsx` - Row filters & column masks
- `SnapshotPanel.tsx` - Timeline view

**State Management** (`useDesignerStore.ts`):
- Zustand store holds current project state
- All mutations generate ops via `emitOps()`
- Ops sent to extension via `vscode.postMessage()`
- Extension applies ops and sends back updated state

### Build System

**Extension**: esbuild (`esbuild.config.mjs`)
- Bundles `src/extension.ts` â†’ `dist/extension.js`
- External: `vscode` module

**Webview**: Vite (`vite.config.ts`)
- Builds React app â†’ `media/`
- Entry: `src/webview/main.tsx`
- Output: `media/index.html`, `media/assets/index.js`, `media/assets/index.css`

**Scripts**:
- `npm run build` - Build both
- `npm run build:ext` - Extension only
- `npm run build:webview` - Webview only
- `npm run watch` - Watch mode (both)

## Python SDK & CLI

### Package Structure

**Location**: `packages/python-sdk/`

**Core Modules**:
- `storage_v4.py` - V4 file I/O with multi-environment support
- `storage_v3.py` - V3 file I/O (deprecated)
- `deployment_tracker.py` - Database-backed deployment tracking
- `cli.py` - Click-based CLI routing layer

**Provider Architecture** (`providers/`):
- `base/` - Provider contracts (models, operations, SQL generation, execution)
- `unity/` - Unity Catalog implementation
  - `models.py` - Pydantic models
  - `operations.py` - Operation types (29 operations)
  - `sql_generator.py` - SQL DDL generation with catalog mapping
  - `state_reducer.py` - State reducer
  - `provider.py` - Provider implementation
  - `auth.py` - Databricks authentication helpers
  - `executor.py` - SQL execution via Databricks API
- `registry.py` - Provider registry

**Command Modules** (`commands/`):
- `apply.py` - Apply SQL to environment with deployment tracking
- `sql.py` - Generate SQL migrations
- `validate.py` - Validate project files
- `deployment.py` - Manual deployment recording

### CLI Commands

```bash
# Generate SQL migration (with environment-specific catalog mapping)
schematic sql [--output FILE] [--target ENV]

# Apply SQL to environment with deployment tracking
schematic apply --target ENV --profile PROFILE --warehouse-id WAREHOUSE_ID [--sql FILE] [--dry-run] [--no-interaction]

# Validate schema files
schematic validate [workspace_path]

# Record deployment manually
schematic record-deployment --environment ENV [--version VERSION] [--mark-deployed]

# Compare versions (stub)
schematic diff VERSION1 VERSION2
```

### Python API

```python
from pathlib import Path
from schematic.storage_v4 import load_current_state, read_project, get_environment_config
from schematic.providers.unity.sql_generator import UnitySQLGenerator

# Load schema
state, changelog, provider = load_current_state(Path.cwd())

# Get environment config
project = read_project(Path.cwd())
env_config = get_environment_config(project, "dev")

# Build catalog mapping
catalog_mapping = {"__implicit__": env_config["catalog"]}

# Generate environment-specific SQL
generator = UnitySQLGenerator(state, catalog_mapping)
sql = generator.generate_sql(changelog["ops"])
```

### Deployment Tracking

**Database-backed tracking** in `{catalog}.schematic` schema:

Tables:
- `deployments` - Main deployment records
- `deployment_ops` - Individual operation tracking

**Local tracking** in `project.json` â†’ `deployments` array

**Execution Flow** (`schematic apply`):
1. Authenticate with Databricks
2. Execute SQL statements (creates catalog if needed)
3. Create tracking schema in `{catalog}.schematic`
4. Record deployment to database
5. Track individual operations
6. Save deployment record to local `project.json`

### Code Formatting

**Python**: Uses Black with 100 character line length

```bash
cd packages/python-sdk
black src/ --line-length 100
```

**Configuration** (`pyproject.toml`):
```toml
[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311', 'py312']
```

## Operation Types (Complete List - 31 Unity Catalog Operations)

**Catalog Operations** (4):
- `add_catalog` - payload: `{catalogId, name, managedLocationName?}`
- `rename_catalog` - payload: `{newName}`
- `update_catalog` - payload: `{managedLocationName?}` - Update catalog properties (e.g., managed location)
- `drop_catalog` - payload: `{}`

**Schema Operations** (4):
- `add_schema` - payload: `{schemaId, name, catalogId, managedLocationName?}`
- `rename_schema` - payload: `{newName}`
- `update_schema` - payload: `{managedLocationName?}` - Update schema properties (e.g., managed location)
- `drop_schema` - payload: `{}`

**Table Operations** (6):
- `add_table` - payload: `{tableId, name, schemaId, format, external?, externalLocationName?, path?, partitionColumns?, clusterColumns?, managedLocationName?}`
- `rename_table` - payload: `{newName}`
- `drop_table` - payload: `{}`
- `set_table_comment` - payload: `{tableId, comment}`
- `set_table_property` - payload: `{tableId, key, value}`
- `unset_table_property` - payload: `{tableId, key}`

**Column Operations** (7):
- `add_column` - payload: `{tableId, colId, name, type, nullable, comment?}`
- `rename_column` - payload: `{tableId, colId, newName}`
- `drop_column` - payload: `{tableId, colId}`
- `reorder_columns` - payload: `{tableId, order: string[]}`
- `change_column_type` - payload: `{tableId, colId, newType}`
- `set_nullable` - payload: `{tableId, colId, nullable}`
- `set_column_comment` - payload: `{tableId, colId, comment}`

**Column Tag Operations** (2):
- `set_column_tag` - payload: `{tableId, colId, tagName, tagValue}`
- `unset_column_tag` - payload: `{tableId, colId, tagName}`

**Constraint Operations** (2):
- `add_constraint` - payload: `{tableId, constraintId, type, name?, columns, ...typeSpecificFields}`
- `drop_constraint` - payload: `{tableId, constraintId}`

**Row Filter Operations** (3):
- `add_row_filter` - payload: `{tableId, filterId, name, udfExpression, enabled?, description?}`
- `update_row_filter` - payload: `{tableId, filterId, name?, udfExpression?, enabled?, description?}`
- `remove_row_filter` - payload: `{tableId, filterId}`

**Column Mask Operations** (3):
- `add_column_mask` - payload: `{tableId, maskId, columnId, name, maskFunction, enabled?, description?}`
- `update_column_mask` - payload: `{tableId, maskId, name?, maskFunction?, enabled?, description?}`
- `remove_column_mask` - payload: `{tableId, maskId}`

## Implementation Status

### âœ… Completed Features (v0.2.0)

**Core Functionality**:
- âœ… Visual schema designer (VS Code extension)
- âœ… Snapshot-based versioning
- âœ… Operation log architecture
- âœ… All 29 Unity Catalog operation types
- âœ… Inline column editing
- âœ… Context-aware UI elements
- âœ… Implicit catalog mode for single-catalog projects

**Multi-Environment Support (V4)**:
- âœ… Project schema v4 with rich environment configurations
- âœ… Environment-specific catalog mapping (logical â†’ physical)
  - Fixed: Catalog name mapping now correctly applies during SQL generation
  - `__implicit__` and logical names resolve to physical names per environment
- âœ… `dev`, `test`, `prod` environment templates
- âœ… Per-environment settings (allowDrift, requireSnapshot, autoCreateCatalog, etc.)
- âœ… Environment-specific SQL generation with resolved names
- âœ… Custom environment wizard with presets
- âœ… Project-level managed locations (for catalog/schema MANAGED LOCATION)
- âœ… Project-level external locations (for external tables)
- âœ… Environment-specific location path resolution

**Data Governance & Storage**:
- âœ… Column tags (key-value metadata)
- âœ… Table constraints (PRIMARY KEY, FOREIGN KEY, CHECK)
- âœ… Row filters (row-level security)
- âœ… Column masks (data masking)
- âœ… Table properties (TBLPROPERTIES)
- âœ… External tables with named external locations
- âœ… Managed locations for catalogs and schemas (physical isolation)
- âœ… Partitioning (PARTITIONED BY)
- âœ… Liquid Clustering (CLUSTER BY)

**SQL Generation**:
- âœ… TypeScript implementation (VS Code)
- âœ… Python implementation (SDK/CLI)
- âœ… Idempotent DDL statements
- âœ… All 31 Unity Catalog operations supported (added UPDATE_CATALOG, UPDATE_SCHEMA)
- âœ… Environment-specific catalog name mapping (fixed: id_name_map rebuild)
- âœ… SQL dependency ordering (catalog â†’ schema â†’ table â†’ operations)
- âœ… SQL file export with environment suffix
- âœ… Unified operation batching (catalogs, schemas, tables)
- âœ… CREATE + UPDATE squashing optimization (single CREATE statement)
- âœ… External location path resolution per environment

**Databricks Integration**:
- âœ… `schematic apply` command for executing SQL
- âœ… Databricks CLI profile authentication
- âœ… SQL Statement Execution API integration
- âœ… Fail-fast execution with error handling
- âœ… Terraform-like preview with confirmation
- âœ… Dry-run mode and no-interaction mode

**Deployment Tracking**:
- âœ… Database-backed tracking in `{catalog}.schematic` schema
- âœ… `deployments` and `deployment_ops` tables
- âœ… Local tracking in `project.json`
- âœ… Deployment status tracking (success/failed/partial)
- âœ… Individual operation tracking
- âœ… Execution time and error logging

**Python SDK & CLI**:
- âœ… Provider-based architecture (Unity Catalog)
- âœ… Modular command structure (`commands/` folder)
- âœ… CLI commands: `apply`, `sql`, `validate`, `record-deployment`
- âœ… Python API for custom scripts
- âœ… Databricks authentication helpers
- âœ… Black code formatting (100 char line length)
- âœ… Ruff linting

**Testing**:
- âœ… 138 passing pytest tests (unit + integration)
- â­ï¸ 12 tests skipped (features in development)
- âœ… Test coverage for v4 storage, catalog mapping, auth, executor
- âœ… SQLGlot validation for generated SQL
- âœ… OperationBuilder pattern for test utilities
- âœ… Smoke tests (extension build, SDK install, CLI validation)

**Infrastructure**:
- âœ… Monorepo structure
- âœ… CI/CD workflows (GitHub Actions)
- âœ… Comprehensive documentation
- âœ… Quality checks pipeline (formatting, linting, tests)
- âœ… Examples and templates

### â­ï¸ Future Enhancements (Not Yet Implemented)

**Databricks Integration**:
- Schema import from Databricks
- Drift detection and reconciliation
- Databricks Asset Bundle (DAB) generation
- Multi-table transaction support
- Rollback statements generation

**Testing**:
- Real integration tests against Databricks workspace
- End-to-end tests for `schematic apply`
- Performance tests for large schemas
- Concurrency tests

**Advanced Features**:
- Visual diff viewer
- Template library
- Multi-catalog project support
- Constraint validation UI
- Multi-user collaboration
- Schema versioning with git integration

**Tooling**:
- VS Code Marketplace publication
- PyPI package publication
- Homebrew formula
- Docker images

## Documentation Structure

**Clean, focused documentation** - no redundant files!

**Root Level**:
- `README.md` - Project overview & quick start
- `TESTING.md` - Testing guide
- `CONTRIBUTING.md` - Contributing guidelines (with code formatting standards)

**docs/ Directory**:
- `README.md` - Documentation index & navigation
- `QUICKSTART.md` - Complete getting started guide
- `ARCHITECTURE.md` - Technical design & concepts
- `DEVELOPMENT.md` - Development guide

**Package Documentation**:
- `packages/vscode-extension/README.md` - Extension-specific
- `packages/vscode-extension/CHANGELOG.md` - Version history
- `packages/python-sdk/README.md` - SDK & CLI reference

**Examples**:
- `examples/basic-schema/` - Sample project
- `examples/github-actions/` - CI/CD templates
- `examples/python-scripts/` - SDK usage examples

## Coding Guidelines

### General Principles

1. **Logging**: Always use `outputChannel.appendLine()` in extension, never `console.log()`
2. **File Structure**: All Schematic files in `.schematic/` folder
3. **Immutability**: Never mutate state directly, always create new objects
4. **Op IDs**: Always generate UUIDs for new ops: `id: \`op_${uuidv4()}\``
5. **Validation**: TypeScript (Zod) and Python (Pydantic) for all data models
6. **Error Handling**: Catch errors, log details, show user-friendly messages
7. **Free-form Input**: Allow SQL expressions freely (no restrictive dropdowns)
8. **Modal Dialogs**: Use custom React modals (webview is sandboxed)
9. **Type Safety**: TypeScript strict mode, Python type hints
10. **State Management**: All mutations via Zustand â†’ emit ops â†’ apply â†’ update UI

### TypeScript

**Standards**:
- Use TypeScript strict mode
- Avoid `any` types
- 2 spaces indentation
- Single quotes for strings
- Max line length: 100 characters
- Semicolons required

**Naming**:
- `camelCase` for variables and functions
- `PascalCase` for types, interfaces, and classes
- `UPPER_CASE` for constants

**Example**:
```typescript
// âœ… Good
interface TableOptions {
  format: 'delta' | 'iceberg';
  properties?: Record<string, string>;
}

export async function createTable(
  name: string,
  options: TableOptions
): Promise<Table> {
  try {
    const table = await tableService.create(name, options);
    outputChannel.appendLine(`[Schematic] Created table: ${name}`);
    return table;
  } catch (error) {
    outputChannel.appendLine(`[Schematic] ERROR: ${error}`);
    throw new Error(`Failed to create table: ${error}`);
  }
}
```

### Python

**Standards**:
- Use Ruff formatter (100 char line length)
- Type hints for all function signatures (REQUIRED - see below)
- Use Pydantic models for data structures
- Follow PEP 8
- Docstrings for public APIs

**Type Annotations (REQUIRED)**:

ALL function and method definitions MUST include complete type annotations:

```python
# âœ… GOOD - Complete type annotations
def process_data(name: str, count: int, options: Optional[Dict[str, Any]] = None) -> List[str]:
    """Process data and return results"""
    return []

def __init__(self, config: Config) -> None:
    """Initialize with config"""
    self.config = config

# âŒ BAD - Missing type annotations
def process_data(name, count, options=None):
    return []

def __init__(self, config):
    self.config = config
```

**Type Annotation Rules**:
1. âœ… ALL parameters must have type hints (except `self` and `cls`)
2. âœ… Return type must be specified (use `-> None` for void functions)
3. âœ… Use `Optional[Type]` for parameters with `None` default
4. âœ… Use `List`, `Dict`, `Tuple` from `typing` module (or `list`, `dict` for Python 3.9+)
5. âœ… Use `Any` sparingly - prefer specific types
6. âœ… Complex types: Use `Union`, `Literal`, `TypeVar` as needed

**More Examples**:
```python
from typing import Any, Dict, Generator, List, Optional, Tuple, Union

# Simple function
def add(a: int, b: int) -> int:
    return a + b

# Optional parameters
def create_user(name: str, email: Optional[str] = None) -> User:
    return User(name=name, email=email)

# Complex types
def process_records(
    data: List[Dict[str, Any]],
    filters: Optional[Dict[str, Union[str, int]]] = None
) -> Tuple[List[Record], int]:
    return [], 0

# Generator functions
def iter_items(data: List[str]) -> Generator[str, None, None]:
    for item in data:
        yield item

# Pydantic models
def validate_config(config: Dict[str, Any]) -> Config:
    return Config(**config)

# Protocol/Interface
def get_executor(config: ExecutionConfig) -> SQLExecutor:
    return UnitySQLExecutor(config)
```

**Enforcement**:
- Pre-commit hooks check with mypy
- VS Code/Cursor shows errors inline
- CI/CD blocks PRs with missing type annotations

**Naming**:
- `snake_case` for variables, functions, and methods
- `PascalCase` for classes
- `UPPER_CASE` for constants

**Formatting**:
```bash
# Format code before committing
cd packages/python-sdk
black src/ --line-length 100
```

**Example**:
```python
# âœ… Good
from typing import List
from pydantic import BaseModel

class Table(BaseModel):
    id: str
    name: str
    columns: List[Column] = []

def create_table(name: str, schema_id: str) -> Table:
    """Create a new table in the specified schema.
    
    Args:
        name: Table name
        schema_id: Parent schema ID
        
    Returns:
        Table: Created table object
        
    Raises:
        ValueError: If name is invalid
    """
    if not name:
        raise ValueError("Table name cannot be empty")
    
    return Table(id=f"table_{uuid4().hex[:8]}", name=name)
```

### Documentation

**When to Update**:
- Feature added â†’ Update relevant docs + README
- Architecture changed â†’ Update `docs/ARCHITECTURE.md`
- Build process changed â†’ Update `docs/DEVELOPMENT.md`
- New test â†’ Update `TESTING.md`

**Best Practices**:
- âœ… Keep single source of truth per topic
- âœ… Use clear, concise language
- âœ… Include code examples
- âœ… Add cross-references
- âŒ Don't create duplicate documentation
- âŒ Don't create redundant status/summary files

## Local Development Workflow

### Before Every Commit/PR

**Always run the complete quality checks**:
```bash
# Run all checks (formatting, linting, tests, smoke tests)
./devops/run-checks.sh
```

This script runs:
1. âœ… Python code formatting check (Black, 100 char line length)
2. âœ… Python linting (Ruff)
3. âœ… Python SDK tests (pytest - 138 passing, 12 skipped)
4. âœ… Smoke tests (extension build, SDK install, CLI validation)

**Exit code 0** = All checks passed, ready to commit
**Exit code 1** = One or more checks failed, fix before committing

---

### Quick Commands Reference

**Python SDK Testing**:
```bash
cd packages/python-sdk

# Run all tests (fast)
pytest tests/ -q

# Run with verbose output
pytest tests/ -v

# Run specific test file
pytest tests/unit/test_sql_generator.py -v

# Run specific test
pytest tests/unit/test_sql_generator.py::TestCatalogSQL::test_add_catalog -xvs

# Run with coverage
pytest tests/ --cov=src/schematic --cov-report=term-missing

# Run with coverage HTML report
pytest tests/ --cov=src/schematic --cov-report=html
open htmlcov/index.html
```

**Python Formatting & Linting**:
```bash
cd packages/python-sdk

# Check formatting (Black)
black src/ tests/ --check --line-length 100

# Fix formatting (Black)
black src/ tests/ --line-length 100

# Or use Ruff format (faster, recommended)
ruff format src/ tests/

# Check linting
ruff check src/ tests/

# Fix linting issues
ruff check src/ tests/ --fix

# Fix with unsafe fixes (removes unused variables, etc.)
ruff check src/ tests/ --fix --unsafe-fixes
```

**VS Code Extension Testing**:
```bash
cd packages/vscode-extension

# Build extension
npm run build

# Build in watch mode (for development)
npm run watch

# Build webview only
npm run build:webview

# Manual testing: Press F5 in VS Code
```

---

### Installation for Local Development

**One-time setup**:
```bash
# Install Python dev dependencies (pytest, ruff, SQLGlot, etc.)
cd packages/python-sdk
pip install -e ".[dev]"

# Or use UV (faster)
uv pip install -e ".[dev]"

# Install VS Code extension dependencies
cd packages/vscode-extension
npm install

# Install root dependencies
cd ../..
npm install
```

---

### SQLGlot Validation

SQLGlot is used in tests to validate generated SQL syntax for Databricks dialect:
```python
# In tests - SQLGlot validates all generated SQL
def test_add_catalog(sample_unity_state, assert_sql):
    result = generator.generate_sql_for_operation(op)
    assert_sql(result.sql)  # âœ… Validates Databricks SQL syntax
```

**Install**:
```bash
cd packages/python-sdk
pip install sqlglot>=20.0.0
# Or included in dev dependencies: pip install -e ".[dev]"
```

---

### CI/CD Pipeline

The quality checks pipeline runs automatically on:
- Push to `main` or `develop`
- Pull requests to `main` or `develop`
- Manual trigger

**Pipeline jobs**:
1. **code-formatting**: Black + Ruff checks
2. **python-tests**: 138 pytest tests + coverage reporting (12 skipped)
3. **smoke-tests**: Extension build + SDK validation
4. **commit-signatures**: GPG signature verification

**Status**: âœ… All checks configured and passing locally

---

## Testing

**Quick Smoke Test**:
```bash
./scripts/smoke-test.sh
```

**VS Code Extension**:
1. Press F5 in VS Code (launches Extension Development Host)
2. Open a workspace folder
3. Cmd+Shift+P â†’ "Schematic: Open Designer"
4. Check logs: View â†’ Output â†’ "Schematic"

**Python CLI**:
```bash
cd packages/python-sdk
pip install -e .
schematic validate examples/basic-schema/
schematic sql
```

**Current Test Status**:
- âœ… 138 pytest tests passing
- â­ï¸ 12 tests skipped (features in development - see issues #19, #20)
- âœ… SQLGlot validation integrated
- âœ… Code coverage reporting enabled
- âœ… OperationBuilder pattern for test utilities
- âœ… Test coverage: v4 storage, catalog mapping, auth, executor, deployment tracking

**V4 Test Files**:
- `test_storage_v4.py` - V4 storage with multi-environment support (19 tests)
- `test_catalog_mapping.py` - Logical â†’ Physical catalog name mapping (8 tests)
- `test_unity_executor.py` - Databricks SQL executor & authentication (6 tests)
- `test_deployment_tracker.py` - Deployment tracking (1 test)
- `test_workflows.py` - Integration tests for complete workflows (8 tests)

**Note**: V3 storage tests removed as v3 is deprecated in favor of v4.

**See**: `TESTING.md` for comprehensive testing guide

## Important Files

**VS Code Extension**:
- `packages/vscode-extension/src/extension.ts` - Extension host
- `packages/vscode-extension/src/storage-v4.ts` - V4 storage layer (multi-environment support)
- `packages/vscode-extension/src/providers/base/sql-generator.ts` - SQL generation
- `packages/vscode-extension/src/providers/base/models.ts` - TypeScript types
- `packages/vscode-extension/src/providers/base/operations.ts` - Op definitions
- `packages/vscode-extension/src/webview/state/useDesignerStore.ts` - Zustand store

**Python SDK**:
- `packages/python-sdk/src/schematic/providers/base/models.py` - Pydantic models
- `packages/python-sdk/src/schematic/providers/base/executor.py` - SQL execution protocol
- `packages/python-sdk/src/schematic/storage_v4.py` - File I/O (v4 multi-environment)
- `packages/python-sdk/src/schematic/providers/unity/state_reducer.py` - State reducer
- `packages/python-sdk/src/schematic/providers/unity/sql_generator.py` - SQL generation with catalog mapping
- `packages/python-sdk/src/schematic/providers/unity/executor.py` - Databricks SQL executor
- `packages/python-sdk/src/schematic/providers/unity/auth.py` - Databricks authentication
- `packages/python-sdk/src/schematic/deployment_tracker.py` - Deployment tracking
- `packages/python-sdk/src/schematic/cli.py` - CLI routing layer
- `packages/python-sdk/src/schematic/commands/apply.py` - Apply command
- `packages/python-sdk/src/schematic/commands/sql.py` - SQL generation command
- `packages/python-sdk/src/schematic/commands/validate.py` - Validation command
- `packages/python-sdk/src/schematic/commands/deployment.py` - Deployment recording

**Documentation**:
- `README.md` - Project overview
- `docs/QUICKSTART.md` - Getting started
- `docs/ARCHITECTURE.md` - Technical design
- `TESTING.md` - Testing guide
- `CONTRIBUTING.md` - Contributing with code formatting

## Unity Catalog Compliance

Based on official Databricks documentation:

1. **Column Tags**: Key-value pairs for metadata tagging and data governance
2. **Constraints**: PRIMARY KEY, FOREIGN KEY, CHECK (informational, not enforced)
3. **Row Filters**: UDF expressions for row-level security
4. **Column Masks**: UDF functions for column-level data masking
5. **Table Properties**: TBLPROPERTIES for Delta Lake configuration

All features implemented according to official Databricks Unity Catalog specifications.

## VS Code API Usage

**Key APIs**:
- `vscode.window.createWebviewPanel()` - Create webview
- `vscode.window.createOutputChannel()` - Logging
- `vscode.commands.registerCommand()` - Register commands
- `webview.postMessage()` / `webview.onDidReceiveMessage()` - Communication
- `vscode.workspace.workspaceFolders` - Get workspace path
- `vscode.window.showInputBox()` - User input
- `vscode.window.withProgress()` - Progress indicator

## Dependencies

**VS Code Extension**:
- Runtime: `uuid`, `zod`, `react`, `react-dom`, `zustand`
- Dev: `typescript`, `esbuild`, `vite`, `@vitejs/plugin-react`, `@vscode/vsce`

**Python SDK**:
- Runtime: `pydantic>=2.0.0`, `click>=8.0.0`, `rich>=13.0.0`, `pyyaml>=6.0.0`, `databricks-sdk>=0.1.0`
- Dev: `pytest>=7.0.0`, `pytest-cov>=4.0.0`, `ruff>=0.1.0`, `mypy>=1.0.0`, `sqlglot>=20.0.0`

## Git Strategy

**Recommended**:
- Commit `.schematic/` folder to git
- Snapshots = tagged releases
- Changelog = work in progress
- Easy to see what changed between versions

## Quick Reference for AI Assistants

When starting a new conversation about this project:

1. **Project Type**: Monorepo with VS Code extension (TypeScript) + Python SDK/CLI
2. **Architecture**: Event sourcing with snapshots + changelog
3. **Storage**: V4 architecture with multi-environment support
   - Python: `packages/python-sdk/src/schematic/storage_v4.py`
   - TypeScript: `packages/vscode-extension/src/storage-v4.ts`
4. **UI**: React webview with inline editing, implicit catalog mode, comprehensive governance features
5. **State**: Snapshot + changelog = current state
6. **SQL Generation**: âœ… Implemented in both TypeScript and Python with environment-specific catalog mapping
   - **Fixed**: id_name_map now correctly rebuilds after setting catalog_name_mapping
   - Unified batching for catalogs, schemas, and tables (uses base class batcher)
   - CREATE + UPDATE squashing optimization (e.g., single CREATE CATALOG ... MANAGED LOCATION)
7. **Deployment Tracking**: âœ… Fully implemented
   - Database-backed in `{catalog}.schematic` schema (Unity Catalog)
   - Local tracking in `project.json` â†’ `deployments` array
8. **Databricks Integration**: âœ… `schematic apply` command with SQL execution, authentication, deployment tracking
9. **Operations**: Provider-based architecture (Unity Catalog = 31 operations)
   - Added: `update_catalog`, `update_schema` for managed location changes
10. **Catalog Mapping**: Logical names (`__implicit__`, explicit) â†’ Physical names per environment
11. **External Tables**: âœ… Fully supported
   - Named external locations with per-environment paths (project-level config)
   - External location path resolution in SQL generation
   - Partitioning (PARTITIONED BY) and Liquid Clustering (CLUSTER BY)
12. **Physical Isolation**: âœ… Managed locations for catalogs/schemas (project-level config)
13. **Logs**: Check "Schematic" output channel in VS Code
14. **Build**: Extension (`npm run build`), SDK (`pip install -e ".[dev]"`)
15. **Code Formatting**: Ruff/Black for Python (100 char), manual for TypeScript
16. **Documentation**: Clean structure, no redundant files
17. **Testing**: 
    - **Before committing**: Run `./devops/run-checks.sh` (includes all checks)
    - **Python tests**: `pytest tests/ -v` (138 passing, 12 skipped)
    - **Smoke test**: `./scripts/smoke-test.sh`
    - **SQLGlot validation**: Integrated in pytest tests
    - **V4 test coverage**: storage_v4, catalog_mapping, unity_executor, deployment_tracker, integration workflows
    - **Note**: V3 storage tests removed (deprecated)
18. **Quality Checks**: Code formatting, linting, pytest, smoke tests all automated
19. **Project Schema**: V4 with project-level location configs and per-environment paths
20. **CLI Commands**: `apply`, `sql`, `validate`, `record-deployment`, `diff` (stub)
21. **Execution Flow**: Authenticate â†’ Execute SQL â†’ Create tracking schema â†’ Record deployment

**Status**: Production-ready v0.2.0 with complete Unity Catalog governance, multi-environment support, and Databricks integration. Future: Schema import, drift detection, DAB generation, multi-catalog support.

## Key Design Patterns

1. **Webview Sandboxing**: Custom React modals (browser APIs blocked)
2. **Type Safety**: Zod (TS) and Pydantic (Python) for runtime validation
3. **Operation Log**: Append-only, immutable, replayable
4. **Snapshot + Changelog**: Bounded growth, clean diffs
5. **Free-form SQL**: Textarea inputs for flexibility
6. **Badge UI**: Compact display for variable-length lists
7. **Context-aware UI**: Dynamic buttons based on selection
8. **Inline Editing**: Faster UX, less context switching
9. **Enable/Disable Toggle**: Non-destructive testing of governance rules
10. **Dual Implementation**: Same logic in TypeScript and Python for consistency
11. **Black Formatting**: Automated Python code formatting (100 char)
12. **Documentation Standards**: Single source of truth, no duplication
13. **Provider-Based Architecture**: Pluggable providers (Unity, Hive, Postgres) with shared contracts
14. **Catalog Name Mapping**: Logical â†’ Physical catalog names per environment
15. **Implicit Catalog Mode**: Hidden catalog level for single-catalog projects
16. **SQL Dependency Ordering**: Catalog â†’ Schema â†’ Table â†’ Operations
17. **Fail-Fast Execution**: Stop on first error, detailed error reporting
18. **Database-Backed Tracking**: Deployment history stored in target catalog
19. **Terraform-Like Preview**: Show changes before execution with confirmation
20. **Execution Flow**: SQL first â†’ Tracking schema after (catalog must exist)
