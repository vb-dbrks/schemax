# Schematic - Project Context

## Overview
Schematic is a comprehensive toolkit for managing Databricks Unity Catalog schemas using a declarative, version-controlled approach. It consists of a VS Code extension for visual schema design and a Python SDK/CLI for automation and CI/CD integration.

## Repository Structure (Monorepo)

```
schematic/
├── packages/
│   ├── vscode-extension/       # VS Code Extension (TypeScript + React)
│   │   ├── src/
│   │   │   ├── extension.ts           # Extension commands
│   │   │   ├── storage-v4.ts          # V4 file storage (multi-environment)
│   │   │   ├── providers/             # Provider-based architecture
│   │   │   │   ├── base/             # Base provider contracts
│   │   │   │   │   ├── models.ts     # Zod schemas
│   │   │   │   │   ├── operations.ts # Operation definitions
│   │   │   │   │   └── sql-generator.ts # SQL generation
│   │   │   │   └── unity/            # Unity Catalog provider
│   │   │   │       ├── sql-generator.ts
│   │   │   │       ├── state-reducer.ts
│   │   │   │       └── operations.ts
│   │   │   └── webview/               # React UI
│   │   └── package.json
│   │
│   └── python-sdk/             # Python SDK & CLI
│       ├── src/schematic/
│       │   ├── providers/             # Provider-based architecture
│       │   │   ├── base/             # Base provider contracts
│       │   │   │   ├── models.py     # Pydantic models
│       │   │   │   ├── operations.py # Operation types
│       │   │   │   ├── sql_generator.py  # SQL generation
│       │   │   │   ├── provider.py   # Provider protocol
│       │   │   │   └── executor.py   # SQL execution protocol
│       │   │   ├── unity/            # Unity Catalog provider
│       │   │   │   ├── models.py
│       │   │   │   ├── operations.py
│       │   │   │   ├── sql_generator.py
│       │   │   │   ├── state_reducer.py
│       │   │   │   ├── provider.py
│       │   │   │   ├── auth.py       # Databricks authentication
│       │   │   │   └── executor.py   # Databricks SQL executor
│       │   │   └── registry.py       # Provider registry
│       │   ├── commands/              # CLI command modules
│       │   │   ├── apply.py          # Apply command
│       │   │   ├── sql.py            # SQL generation command
│       │   │   ├── validate.py       # Validation command
│       │   │   └── deployment.py     # Deployment recording
│       │   ├── storage_v4.py          # V4 file storage (multi-environment)
│       │   ├── storage_v3.py          # V3 file storage (deprecated)
│       │   ├── deployment_tracker.py  # Deployment tracking
│       │   └── cli.py                 # CLI routing layer
│       └── pyproject.toml
│
├── examples/                   # Working examples
│   ├── basic-schema/          # Sample project
│   ├── github-actions/        # CI/CD templates
│   └── python-scripts/        # SDK usage examples
│
├── docs/                       # Documentation
│   ├── README.md              # Documentation index
│   ├── QUICKSTART.md          # Getting started guide
│   ├── ARCHITECTURE.md        # Technical design
│   └── DEVELOPMENT.md         # Development guide
│
├── scripts/
│   └── smoke-test.sh          # Quick validation
│
├── .github/workflows/          # CI/CD pipelines
│   ├── extension-ci.yml
│   ├── python-sdk-ci.yml
│   └── integration-tests.yml
│
├── README.md                   # Project overview
├── TESTING.md                  # Testing guide
├── CONTRIBUTING.md             # Contributing guidelines
└── .cursorrules               # This file
```

## Architecture (V4)

### File Structure (.schematic/)
```
project-root/
└── .schematic/
    ├── project.json           # Project metadata (version, snapshots list, settings)
    ├── changelog.json         # Working changes (ops since last snapshot)
    ├── snapshots/
    │   ├── v0.1.0.json       # Full state snapshots
    │   ├── v0.2.0.json
    │   └── v0.3.0.json
    └── migrations/            # Generated SQL files
        └── migration_*.sql
```

### Core Concepts

1. **Operations (Ops)**: Append-only log of all user actions
   - Each op has: `{id, ts, op, target, payload}`
   - Ops are immutable and never edited
   - Examples: `add_catalog`, `rename_column`, `reorder_columns`
   - All ops have UUIDs for tracking

2. **Changelog**: `changelog.json` contains ops since last snapshot
   - Cleared when snapshot is created
   - Tracks `sinceSnapshot` version
   - This is the "working directory" of changes

3. **Snapshots**: Point-in-time full state captures
   - Stored as separate files: `.schematic/snapshots/vX.Y.Z.json`
   - Contains complete state + list of ops included
   - Metadata stored in `project.json`, full state in snapshot file
   - Semantic versioning (v0.1.0, v0.2.0, etc.)

4. **State Loading**: 
   - Load latest snapshot (or start with empty state)
   - Apply changelog ops to get current state
   - This is what the UI displays

5. **SQL Generation**: 
   - Convert changelog ops to SQL DDL
   - Idempotent statements (safe to run multiple times)
   - Saved to `.schematic/migrations/` directory

### Data Models

**Project File** (`project.json` - v4 Schema):
```typescript
{
  version: 4,
  name: string,
  provider: {
    type: string,  // e.g., "unity"
    version: string,  // e.g., "1.0.0"
    environments: {
      [envName: string]: {
        catalog: string,  // Physical catalog name
        description?: string,
        allowDrift: boolean,
        requireSnapshot: boolean,
        requireApproval?: boolean,
        autoCreateCatalog: boolean,
        autoCreateSchematicSchema: boolean
      }
    }
  },
  snapshots: SnapshotMetadata[], // Just metadata, references to files
  deployments: Deployment[],
  settings: ProjectSettings,
  latestSnapshot: string | null  // version string
}
```

**Note:** v4 replaces v3's simple environments array with rich environment configuration objects.

**Changelog File** (`changelog.json`):
```typescript
{
  version: 1,
  sinceSnapshot: string | null,  // version
  ops: Op[],
  lastModified: string  // ISO timestamp
}
```

**Snapshot File** (`.schematic/snapshots/vX.Y.Z.json`):
```typescript
{
  id: string,
  version: string,
  name: string,
  ts: string,
  createdBy: string,
  state: { catalogs: Catalog[] },  // Full state
  opsIncluded: string[],  // Op IDs
  previousSnapshot: string | null,
  hash: string,  // SHA-256 for integrity
  tags: string[],
  comment?: string
}
```

**Unity Catalog Model** (Enhanced with Governance Features):
```
Catalog
├── Schema[]
    └── Table[]
        ├── columns: Column[]
        │   ├── id, name, type, nullable, comment
        │   ├── tags?: Record<string, string>         // Column-level tags
        │   └── maskId?: string                        // Reference to column mask
        ├── properties: Record<string, string>         // TBLPROPERTIES
        ├── constraints: Constraint[]                  // PK, FK, CHECK
        ├── grants: Grant[]
        ├── rowFilters?: RowFilter[]                   // Row-level security
        └── columnMasks?: ColumnMask[]                 // Column masking
```

**Column**:
```typescript
{
  id: string,
  name: string,
  type: string,
  nullable: boolean,
  comment?: string,
  tags?: Record<string, string>,    // { tag_name: tag_value }
  maskId?: string                    // Reference to active mask
}
```

**Constraint** (Supports PRIMARY KEY, FOREIGN KEY, CHECK):
```typescript
{
  id: string,
  type: 'primary_key' | 'foreign_key' | 'check',
  name?: string,                    // CONSTRAINT name
  columns: string[],                // column IDs
  
  // For PRIMARY KEY
  timeseries?: boolean,             
  
  // For FOREIGN KEY
  parentTable?: string,             
  parentColumns?: string[],         
  matchFull?: boolean,
  onUpdate?: 'NO_ACTION',
  onDelete?: 'NO_ACTION',
  
  // For CHECK
  expression?: string,              // SQL expression
  
  // Constraint options (all types)
  notEnforced?: boolean,            
  deferrable?: boolean,
  initiallyDeferred?: boolean,
  rely?: boolean                    // For Photon query optimization
}
```

**RowFilter** (Row-level security):
```typescript
{
  id: string,
  name: string,
  enabled: boolean,
  udfExpression: string,            // e.g., "region = current_user()"
  description?: string
}
```

**ColumnMask** (Column-level masking):
```typescript
{
  id: string,
  columnId: string,
  name: string,
  enabled: boolean,
  maskFunction: string,             // e.g., "REDACT_EMAIL(email)"
  description?: string
}
```

## VS Code Extension

### Storage Layer (`packages/vscode-extension/src/storage-v4.ts`)

**Key Functions**:
- `ensureProjectFile()` - Initialize new v4 project with environments
- `loadCurrentState()` - Load snapshot + apply changelog
- `appendOps()` - Add ops to changelog
- `createSnapshot()` - Create snapshot file, update metadata, clear changelog
- `readProject()`, `readChangelog()`, `readSnapshot()`
- `getEnvironmentConfig()` - Get environment-specific configuration

**Op Reducer**: `applyOpsToState()` applies ops to state immutably

**Catalog Mode**: Supports `single` mode with implicit catalog (`__implicit__`)

### SQL Generator (`packages/vscode-extension/src/providers/unity/sql-generator.ts`)

**UnitySQLGenerator class**:
- `generateSQL(ops: Op[]): string` - Main entry point
- Accepts `catalogNameMapping` for environment-specific SQL
- Private methods for each operation type
- Generates idempotent DDL (CREATE IF NOT EXISTS, etc.)
- Handles all 29 Unity Catalog operations
- Orders SQL by dependency (catalog → schema → table → operations)
- Includes operation tracking in comments

### Extension (`packages/vscode-extension/src/extension.ts`)

**Commands**:
1. `schematic.openDesigner` - Opens React webview
2. `schematic.showLastOps` - Shows changelog ops
3. `schematic.createSnapshot` - Creates new snapshot
4. `schematic.generateSQL` - Generates SQL migration file

**Message Flow**:
- Webview → Extension: `load-project`, `append-ops`
- Extension → Webview: `project-loaded`, `project-updated`

### Webview (`packages/vscode-extension/src/webview/`)

**Architecture**: React + Vite + Zustand

**Components**:
- `App.tsx` - Main layout, message handling
- `Sidebar.tsx` - Tree view with context-aware inline "+" buttons
- `TableDesigner.tsx` - Comprehensive table editor
- `ColumnGrid.tsx` - Inline column editing + tags
- `TableProperties.tsx` - TBLPROPERTIES management
- `TableConstraints.tsx` - PRIMARY KEY, FOREIGN KEY, CHECK
- `SecurityGovernance.tsx` - Row filters & column masks
- `SnapshotPanel.tsx` - Timeline view

**State Management** (`useDesignerStore.ts`):
- Zustand store holds current project state
- All mutations generate ops via `emitOps()`
- Ops sent to extension via `vscode.postMessage()`
- Extension applies ops and sends back updated state

### Build System

**Extension**: esbuild (`esbuild.config.mjs`)
- Bundles `src/extension.ts` → `dist/extension.js`
- External: `vscode` module

**Webview**: Vite (`vite.config.ts`)
- Builds React app → `media/`
- Entry: `src/webview/main.tsx`
- Output: `media/index.html`, `media/assets/index.js`, `media/assets/index.css`

**Scripts**:
- `npm run build` - Build both
- `npm run build:ext` - Extension only
- `npm run build:webview` - Webview only
- `npm run watch` - Watch mode (both)

## Python SDK & CLI

### Package Structure

**Location**: `packages/python-sdk/`

**Core Modules**:
- `storage_v4.py` - V4 file I/O with multi-environment support
- `storage_v3.py` - V3 file I/O (deprecated)
- `deployment_tracker.py` - Database-backed deployment tracking
- `cli.py` - Click-based CLI routing layer

**Provider Architecture** (`providers/`):
- `base/` - Provider contracts (models, operations, SQL generation, execution)
- `unity/` - Unity Catalog implementation
  - `models.py` - Pydantic models
  - `operations.py` - Operation types (29 operations)
  - `sql_generator.py` - SQL DDL generation with catalog mapping
  - `state_reducer.py` - State reducer
  - `provider.py` - Provider implementation
  - `auth.py` - Databricks authentication helpers
  - `executor.py` - SQL execution via Databricks API
- `registry.py` - Provider registry

**Command Modules** (`commands/`):
- `apply.py` - Apply SQL to environment with deployment tracking
- `sql.py` - Generate SQL migrations
- `validate.py` - Validate project files
- `deployment.py` - Manual deployment recording

### CLI Commands

```bash
# Generate SQL migration (with environment-specific catalog mapping)
schematic sql [--output FILE] [--target ENV]

# Apply SQL to environment with deployment tracking
schematic apply --target ENV --profile PROFILE --warehouse-id WAREHOUSE_ID [--sql FILE] [--dry-run] [--no-interaction]

# Validate schema files
schematic validate [workspace_path]

# Record deployment manually
schematic record-deployment --environment ENV [--version VERSION] [--mark-deployed]

# Compare versions (stub)
schematic diff VERSION1 VERSION2
```

### Python API

```python
from pathlib import Path
from schematic.storage_v4 import load_current_state, read_project, get_environment_config
from schematic.providers.unity.sql_generator import UnitySQLGenerator

# Load schema
state, changelog, provider = load_current_state(Path.cwd())

# Get environment config
project = read_project(Path.cwd())
env_config = get_environment_config(project, "dev")

# Build catalog mapping
catalog_mapping = {"__implicit__": env_config["catalog"]}

# Generate environment-specific SQL
generator = UnitySQLGenerator(state, catalog_mapping)
sql = generator.generate_sql(changelog["ops"])
```

### Deployment Tracking

**Database-backed tracking** in `{catalog}.schematic` schema:

Tables:
- `deployments` - Main deployment records
- `deployment_ops` - Individual operation tracking

**Local tracking** in `project.json` → `deployments` array

**Execution Flow** (`schematic apply`):
1. Authenticate with Databricks
2. Execute SQL statements (creates catalog if needed)
3. Create tracking schema in `{catalog}.schematic`
4. Record deployment to database
5. Track individual operations
6. Save deployment record to local `project.json`

### Code Formatting

**Python**: Uses Black with 100 character line length

```bash
cd packages/python-sdk
black src/ --line-length 100
```

**Configuration** (`pyproject.toml`):
```toml
[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311', 'py312']
```

## Operation Types (Complete List - 29 Unity Catalog Operations)

**Catalog Operations** (3):
- `add_catalog` - payload: `{catalogId, name}`
- `rename_catalog` - payload: `{newName}`
- `drop_catalog` - payload: `{}`

**Schema Operations** (3):
- `add_schema` - payload: `{schemaId, name, catalogId}`
- `rename_schema` - payload: `{newName}`
- `drop_schema` - payload: `{}`

**Table Operations** (6):
- `add_table` - payload: `{tableId, name, schemaId, format}`
- `rename_table` - payload: `{newName}`
- `drop_table` - payload: `{}`
- `set_table_comment` - payload: `{tableId, comment}`
- `set_table_property` - payload: `{tableId, key, value}`
- `unset_table_property` - payload: `{tableId, key}`

**Column Operations** (7):
- `add_column` - payload: `{tableId, colId, name, type, nullable, comment?}`
- `rename_column` - payload: `{tableId, colId, newName}`
- `drop_column` - payload: `{tableId, colId}`
- `reorder_columns` - payload: `{tableId, order: string[]}`
- `change_column_type` - payload: `{tableId, colId, newType}`
- `set_nullable` - payload: `{tableId, colId, nullable}`
- `set_column_comment` - payload: `{tableId, colId, comment}`

**Column Tag Operations** (2):
- `set_column_tag` - payload: `{tableId, colId, tagName, tagValue}`
- `unset_column_tag` - payload: `{tableId, colId, tagName}`

**Constraint Operations** (2):
- `add_constraint` - payload: `{tableId, constraintId, type, name?, columns, ...typeSpecificFields}`
- `drop_constraint` - payload: `{tableId, constraintId}`

**Row Filter Operations** (3):
- `add_row_filter` - payload: `{tableId, filterId, name, udfExpression, enabled?, description?}`
- `update_row_filter` - payload: `{tableId, filterId, name?, udfExpression?, enabled?, description?}`
- `remove_row_filter` - payload: `{tableId, filterId}`

**Column Mask Operations** (3):
- `add_column_mask` - payload: `{tableId, maskId, columnId, name, maskFunction, enabled?, description?}`
- `update_column_mask` - payload: `{tableId, maskId, name?, maskFunction?, enabled?, description?}`
- `remove_column_mask` - payload: `{tableId, maskId}`

## Implementation Status

### ✅ Completed Features (v0.2.0)

**Core Functionality**:
- ✅ Visual schema designer (VS Code extension)
- ✅ Snapshot-based versioning
- ✅ Operation log architecture
- ✅ All 29 Unity Catalog operation types
- ✅ Inline column editing
- ✅ Context-aware UI elements
- ✅ Implicit catalog mode for single-catalog projects

**Multi-Environment Support (V4)**:
- ✅ Project schema v4 with rich environment configurations
- ✅ Environment-specific catalog mapping (logical → physical)
- ✅ `dev`, `test`, `prod` environment templates
- ✅ Per-environment settings (allowDrift, requireSnapshot, autoCreateCatalog, etc.)
- ✅ Environment-specific SQL generation
- ✅ Custom environment wizard with presets

**Data Governance**:
- ✅ Column tags (key-value metadata)
- ✅ Table constraints (PRIMARY KEY, FOREIGN KEY, CHECK)
- ✅ Row filters (row-level security)
- ✅ Column masks (data masking)
- ✅ Table properties (TBLPROPERTIES)

**SQL Generation**:
- ✅ TypeScript implementation (VS Code)
- ✅ Python implementation (SDK/CLI)
- ✅ Idempotent DDL statements
- ✅ All 29 Unity Catalog operations supported
- ✅ Environment-specific catalog name mapping
- ✅ SQL dependency ordering (catalog → schema → table → operations)
- ✅ SQL file export with environment suffix

**Databricks Integration**:
- ✅ `schematic apply` command for executing SQL
- ✅ Databricks CLI profile authentication
- ✅ SQL Statement Execution API integration
- ✅ Fail-fast execution with error handling
- ✅ Terraform-like preview with confirmation
- ✅ Dry-run mode and no-interaction mode

**Deployment Tracking**:
- ✅ Database-backed tracking in `{catalog}.schematic` schema
- ✅ `deployments` and `deployment_ops` tables
- ✅ Local tracking in `project.json`
- ✅ Deployment status tracking (success/failed/partial)
- ✅ Individual operation tracking
- ✅ Execution time and error logging

**Python SDK & CLI**:
- ✅ Provider-based architecture (Unity Catalog)
- ✅ Modular command structure (`commands/` folder)
- ✅ CLI commands: `apply`, `sql`, `validate`, `record-deployment`
- ✅ Python API for custom scripts
- ✅ Databricks authentication helpers
- ✅ Black code formatting (100 char line length)
- ✅ Ruff linting

**Testing**:
- ✅ 138 passing pytest tests (unit + integration)
- ⏭️ 12 tests skipped (features in development)
- ✅ Test coverage for v4 storage, catalog mapping, auth, executor
- ✅ SQLGlot validation for generated SQL
- ✅ OperationBuilder pattern for test utilities
- ✅ Smoke tests (extension build, SDK install, CLI validation)

**Infrastructure**:
- ✅ Monorepo structure
- ✅ CI/CD workflows (GitHub Actions)
- ✅ Comprehensive documentation
- ✅ Quality checks pipeline (formatting, linting, tests)
- ✅ Examples and templates

### ⏭️ Future Enhancements (Not Yet Implemented)

**Databricks Integration**:
- Schema import from Databricks
- Drift detection and reconciliation
- Databricks Asset Bundle (DAB) generation
- Multi-table transaction support
- Rollback statements generation

**Testing**:
- Real integration tests against Databricks workspace
- End-to-end tests for `schematic apply`
- Performance tests for large schemas
- Concurrency tests

**Advanced Features**:
- Visual diff viewer
- Template library
- Multi-catalog project support
- Constraint validation UI
- Multi-user collaboration
- Schema versioning with git integration

**Tooling**:
- VS Code Marketplace publication
- PyPI package publication
- Homebrew formula
- Docker images

## Documentation Structure

**Clean, focused documentation** - no redundant files!

**Root Level**:
- `README.md` - Project overview & quick start
- `TESTING.md` - Testing guide
- `CONTRIBUTING.md` - Contributing guidelines (with code formatting standards)

**docs/ Directory**:
- `README.md` - Documentation index & navigation
- `QUICKSTART.md` - Complete getting started guide
- `ARCHITECTURE.md` - Technical design & concepts
- `DEVELOPMENT.md` - Development guide

**Package Documentation**:
- `packages/vscode-extension/README.md` - Extension-specific
- `packages/vscode-extension/CHANGELOG.md` - Version history
- `packages/python-sdk/README.md` - SDK & CLI reference

**Examples**:
- `examples/basic-schema/` - Sample project
- `examples/github-actions/` - CI/CD templates
- `examples/python-scripts/` - SDK usage examples

## Coding Guidelines

### General Principles

1. **Logging**: Always use `outputChannel.appendLine()` in extension, never `console.log()`
2. **File Structure**: All Schematic files in `.schematic/` folder
3. **Immutability**: Never mutate state directly, always create new objects
4. **Op IDs**: Always generate UUIDs for new ops: `id: \`op_${uuidv4()}\``
5. **Validation**: TypeScript (Zod) and Python (Pydantic) for all data models
6. **Error Handling**: Catch errors, log details, show user-friendly messages
7. **Free-form Input**: Allow SQL expressions freely (no restrictive dropdowns)
8. **Modal Dialogs**: Use custom React modals (webview is sandboxed)
9. **Type Safety**: TypeScript strict mode, Python type hints
10. **State Management**: All mutations via Zustand → emit ops → apply → update UI

### TypeScript

**Standards**:
- Use TypeScript strict mode
- Avoid `any` types
- 2 spaces indentation
- Single quotes for strings
- Max line length: 100 characters
- Semicolons required

**Naming**:
- `camelCase` for variables and functions
- `PascalCase` for types, interfaces, and classes
- `UPPER_CASE` for constants

**Example**:
```typescript
// ✅ Good
interface TableOptions {
  format: 'delta' | 'iceberg';
  properties?: Record<string, string>;
}

export async function createTable(
  name: string,
  options: TableOptions
): Promise<Table> {
  try {
    const table = await tableService.create(name, options);
    outputChannel.appendLine(`[Schematic] Created table: ${name}`);
    return table;
  } catch (error) {
    outputChannel.appendLine(`[Schematic] ERROR: ${error}`);
    throw new Error(`Failed to create table: ${error}`);
  }
}
```

### Python

**Standards**:
- Use Black formatter (100 char line length)
- Type hints for all function signatures
- Use Pydantic models for data structures
- Follow PEP 8
- Docstrings for public APIs

**Naming**:
- `snake_case` for variables, functions, and methods
- `PascalCase` for classes
- `UPPER_CASE` for constants

**Formatting**:
```bash
# Format code before committing
cd packages/python-sdk
black src/ --line-length 100
```

**Example**:
```python
# ✅ Good
from typing import List
from pydantic import BaseModel

class Table(BaseModel):
    id: str
    name: str
    columns: List[Column] = []

def create_table(name: str, schema_id: str) -> Table:
    """Create a new table in the specified schema.
    
    Args:
        name: Table name
        schema_id: Parent schema ID
        
    Returns:
        Table: Created table object
        
    Raises:
        ValueError: If name is invalid
    """
    if not name:
        raise ValueError("Table name cannot be empty")
    
    return Table(id=f"table_{uuid4().hex[:8]}", name=name)
```

### Documentation

**When to Update**:
- Feature added → Update relevant docs + README
- Architecture changed → Update `docs/ARCHITECTURE.md`
- Build process changed → Update `docs/DEVELOPMENT.md`
- New test → Update `TESTING.md`

**Best Practices**:
- ✅ Keep single source of truth per topic
- ✅ Use clear, concise language
- ✅ Include code examples
- ✅ Add cross-references
- ❌ Don't create duplicate documentation
- ❌ Don't create redundant status/summary files

## Local Development Workflow

### Before Every Commit/PR

**Always run the complete quality checks**:
```bash
# Run all checks (formatting, linting, tests, smoke tests)
./devops/run-checks.sh
```

This script runs:
1. ✅ Python code formatting check (Black, 100 char line length)
2. ✅ Python linting (Ruff)
3. ✅ Python SDK tests (pytest - 138 passing, 12 skipped)
4. ✅ Smoke tests (extension build, SDK install, CLI validation)

**Exit code 0** = All checks passed, ready to commit
**Exit code 1** = One or more checks failed, fix before committing

---

### Quick Commands Reference

**Python SDK Testing**:
```bash
cd packages/python-sdk

# Run all tests (fast)
pytest tests/ -q

# Run with verbose output
pytest tests/ -v

# Run specific test file
pytest tests/unit/test_sql_generator.py -v

# Run specific test
pytest tests/unit/test_sql_generator.py::TestCatalogSQL::test_add_catalog -xvs

# Run with coverage
pytest tests/ --cov=src/schematic --cov-report=term-missing

# Run with coverage HTML report
pytest tests/ --cov=src/schematic --cov-report=html
open htmlcov/index.html
```

**Python Formatting & Linting**:
```bash
cd packages/python-sdk

# Check formatting (Black)
black src/ tests/ --check --line-length 100

# Fix formatting (Black)
black src/ tests/ --line-length 100

# Or use Ruff format (faster, recommended)
ruff format src/ tests/

# Check linting
ruff check src/ tests/

# Fix linting issues
ruff check src/ tests/ --fix

# Fix with unsafe fixes (removes unused variables, etc.)
ruff check src/ tests/ --fix --unsafe-fixes
```

**VS Code Extension Testing**:
```bash
cd packages/vscode-extension

# Build extension
npm run build

# Build in watch mode (for development)
npm run watch

# Build webview only
npm run build:webview

# Manual testing: Press F5 in VS Code
```

---

### Installation for Local Development

**One-time setup**:
```bash
# Install Python dev dependencies (pytest, ruff, SQLGlot, etc.)
cd packages/python-sdk
pip install -e ".[dev]"

# Or use UV (faster)
uv pip install -e ".[dev]"

# Install VS Code extension dependencies
cd packages/vscode-extension
npm install

# Install root dependencies
cd ../..
npm install
```

---

### SQLGlot Validation

SQLGlot is used in tests to validate generated SQL syntax for Databricks dialect:
```python
# In tests - SQLGlot validates all generated SQL
def test_add_catalog(sample_unity_state, assert_sql):
    result = generator.generate_sql_for_operation(op)
    assert_sql(result.sql)  # ✅ Validates Databricks SQL syntax
```

**Install**:
```bash
cd packages/python-sdk
pip install sqlglot>=20.0.0
# Or included in dev dependencies: pip install -e ".[dev]"
```

---

### CI/CD Pipeline

The quality checks pipeline runs automatically on:
- Push to `main` or `develop`
- Pull requests to `main` or `develop`
- Manual trigger

**Pipeline jobs**:
1. **code-formatting**: Black + Ruff checks
2. **python-tests**: 138 pytest tests + coverage reporting (12 skipped)
3. **smoke-tests**: Extension build + SDK validation
4. **commit-signatures**: GPG signature verification

**Status**: ✅ All checks configured and passing locally

---

## Testing

**Quick Smoke Test**:
```bash
./scripts/smoke-test.sh
```

**VS Code Extension**:
1. Press F5 in VS Code (launches Extension Development Host)
2. Open a workspace folder
3. Cmd+Shift+P → "Schematic: Open Designer"
4. Check logs: View → Output → "Schematic"

**Python CLI**:
```bash
cd packages/python-sdk
pip install -e .
schematic validate examples/basic-schema/
schematic sql
```

**Current Test Status**:
- ✅ 138 pytest tests passing
- ⏭️ 12 tests skipped (features in development - see issues #19, #20)
- ✅ SQLGlot validation integrated
- ✅ Code coverage reporting enabled
- ✅ OperationBuilder pattern for test utilities
- ✅ Test coverage: v4 storage, catalog mapping, auth, executor, deployment tracking

**V4 Test Files**:
- `test_storage_v4.py` - V4 storage with multi-environment support (19 tests)
- `test_catalog_mapping.py` - Logical → Physical catalog name mapping (8 tests)
- `test_unity_executor.py` - Databricks SQL executor & authentication (6 tests)
- `test_deployment_tracker.py` - Deployment tracking (1 test)
- `test_workflows.py` - Integration tests for complete workflows (8 tests)

**Note**: V3 storage tests removed as v3 is deprecated in favor of v4.

**See**: `TESTING.md` for comprehensive testing guide

## Important Files

**VS Code Extension**:
- `packages/vscode-extension/src/extension.ts` - Extension host
- `packages/vscode-extension/src/storage-v4.ts` - V4 storage layer (multi-environment support)
- `packages/vscode-extension/src/providers/base/sql-generator.ts` - SQL generation
- `packages/vscode-extension/src/providers/base/models.ts` - TypeScript types
- `packages/vscode-extension/src/providers/base/operations.ts` - Op definitions
- `packages/vscode-extension/src/webview/state/useDesignerStore.ts` - Zustand store

**Python SDK**:
- `packages/python-sdk/src/schematic/providers/base/models.py` - Pydantic models
- `packages/python-sdk/src/schematic/providers/base/executor.py` - SQL execution protocol
- `packages/python-sdk/src/schematic/storage_v4.py` - File I/O (v4 multi-environment)
- `packages/python-sdk/src/schematic/providers/unity/state_reducer.py` - State reducer
- `packages/python-sdk/src/schematic/providers/unity/sql_generator.py` - SQL generation with catalog mapping
- `packages/python-sdk/src/schematic/providers/unity/executor.py` - Databricks SQL executor
- `packages/python-sdk/src/schematic/providers/unity/auth.py` - Databricks authentication
- `packages/python-sdk/src/schematic/deployment_tracker.py` - Deployment tracking
- `packages/python-sdk/src/schematic/cli.py` - CLI routing layer
- `packages/python-sdk/src/schematic/commands/apply.py` - Apply command
- `packages/python-sdk/src/schematic/commands/sql.py` - SQL generation command
- `packages/python-sdk/src/schematic/commands/validate.py` - Validation command
- `packages/python-sdk/src/schematic/commands/deployment.py` - Deployment recording

**Documentation**:
- `README.md` - Project overview
- `docs/QUICKSTART.md` - Getting started
- `docs/ARCHITECTURE.md` - Technical design
- `TESTING.md` - Testing guide
- `CONTRIBUTING.md` - Contributing with code formatting

## Unity Catalog Compliance

Based on official Databricks documentation:

1. **Column Tags**: Key-value pairs for metadata tagging and data governance
2. **Constraints**: PRIMARY KEY, FOREIGN KEY, CHECK (informational, not enforced)
3. **Row Filters**: UDF expressions for row-level security
4. **Column Masks**: UDF functions for column-level data masking
5. **Table Properties**: TBLPROPERTIES for Delta Lake configuration

All features implemented according to official Databricks Unity Catalog specifications.

## VS Code API Usage

**Key APIs**:
- `vscode.window.createWebviewPanel()` - Create webview
- `vscode.window.createOutputChannel()` - Logging
- `vscode.commands.registerCommand()` - Register commands
- `webview.postMessage()` / `webview.onDidReceiveMessage()` - Communication
- `vscode.workspace.workspaceFolders` - Get workspace path
- `vscode.window.showInputBox()` - User input
- `vscode.window.withProgress()` - Progress indicator

## Dependencies

**VS Code Extension**:
- Runtime: `uuid`, `zod`, `react`, `react-dom`, `zustand`
- Dev: `typescript`, `esbuild`, `vite`, `@vitejs/plugin-react`, `@vscode/vsce`

**Python SDK**:
- Runtime: `pydantic>=2.0.0`, `click>=8.0.0`, `rich>=13.0.0`, `pyyaml>=6.0.0`, `databricks-sdk>=0.1.0`
- Dev: `pytest>=7.0.0`, `pytest-cov>=4.0.0`, `ruff>=0.1.0`, `mypy>=1.0.0`, `sqlglot>=20.0.0`

## Git Strategy

**Recommended**:
- Commit `.schematic/` folder to git
- Snapshots = tagged releases
- Changelog = work in progress
- Easy to see what changed between versions

## Quick Reference for AI Assistants

When starting a new conversation about this project:

1. **Project Type**: Monorepo with VS Code extension (TypeScript) + Python SDK/CLI
2. **Architecture**: Event sourcing with snapshots + changelog
3. **Storage**: V4 architecture with multi-environment support
   - Python: `packages/python-sdk/src/schematic/storage_v4.py`
   - TypeScript: `packages/vscode-extension/src/storage-v4.ts`
4. **UI**: React webview with inline editing, implicit catalog mode, comprehensive governance features
5. **State**: Snapshot + changelog = current state
6. **SQL Generation**: ✅ Implemented in both TypeScript and Python with environment-specific catalog mapping
7. **Deployment Tracking**: ✅ Fully implemented
   - Database-backed in `{catalog}.schematic` schema (Unity Catalog)
   - Local tracking in `project.json` → `deployments` array
8. **Databricks Integration**: ✅ `schematic apply` command with SQL execution, authentication, deployment tracking
9. **Operations**: Provider-based architecture (Unity Catalog = 29 operations)
10. **Catalog Mapping**: Logical names (`__implicit__`, explicit) → Physical names per environment
11. **Logs**: Check "Schematic" output channel in VS Code
12. **Build**: Extension (`npm run build`), SDK (`pip install -e ".[dev]"`)
13. **Code Formatting**: Ruff/Black for Python (100 char), manual for TypeScript
14. **Documentation**: Clean structure, no redundant files
15. **Testing**: 
    - **Before committing**: Run `./devops/run-checks.sh` (includes all checks)
    - **Python tests**: `pytest tests/ -v` (138 passing, 12 skipped)
    - **Smoke test**: `./scripts/smoke-test.sh`
    - **SQLGlot validation**: Integrated in pytest tests
    - **V4 test coverage**: storage_v4, catalog_mapping, unity_executor, deployment_tracker, integration workflows
    - **Note**: V3 storage tests removed (deprecated)
16. **Quality Checks**: Code formatting, linting, pytest, smoke tests all automated
17. **Project Schema**: V4 with environment-specific catalog configurations (breaking change from v3)
18. **CLI Commands**: `apply`, `sql`, `validate`, `record-deployment`, `diff` (stub)
19. **Execution Flow**: Authenticate → Execute SQL → Create tracking schema → Record deployment

**Status**: Production-ready v0.2.0 with complete Unity Catalog governance, multi-environment support, and Databricks integration. Future: Schema import, drift detection, DAB generation, multi-catalog support.

## Key Design Patterns

1. **Webview Sandboxing**: Custom React modals (browser APIs blocked)
2. **Type Safety**: Zod (TS) and Pydantic (Python) for runtime validation
3. **Operation Log**: Append-only, immutable, replayable
4. **Snapshot + Changelog**: Bounded growth, clean diffs
5. **Free-form SQL**: Textarea inputs for flexibility
6. **Badge UI**: Compact display for variable-length lists
7. **Context-aware UI**: Dynamic buttons based on selection
8. **Inline Editing**: Faster UX, less context switching
9. **Enable/Disable Toggle**: Non-destructive testing of governance rules
10. **Dual Implementation**: Same logic in TypeScript and Python for consistency
11. **Black Formatting**: Automated Python code formatting (100 char)
12. **Documentation Standards**: Single source of truth, no duplication
13. **Provider-Based Architecture**: Pluggable providers (Unity, Hive, Postgres) with shared contracts
14. **Catalog Name Mapping**: Logical → Physical catalog names per environment
15. **Implicit Catalog Mode**: Hidden catalog level for single-catalog projects
16. **SQL Dependency Ordering**: Catalog → Schema → Table → Operations
17. **Fail-Fast Execution**: Stop on first error, detailed error reporting
18. **Database-Backed Tracking**: Deployment history stored in target catalog
19. **Terraform-Like Preview**: Show changes before execution with confirmation
20. **Execution Flow**: SQL first → Tracking schema after (catalog must exist)
